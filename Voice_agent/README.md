# AI Call Center with Automatic Dialect Detection

Real-time Arabic dialect detection and response system using Gemini 2.5 Flash, Whisper, and XTTS.

## Features

âœ… **Automatic Dialect Detection** - Detects Egyptian, Gulf, Levantine, Moroccan, and MSA  
âœ… **LLM-Based Classification** - Uses Gemini 2.5 Flash (no training required)  
âœ… **Session Dialect Locking** - Maintains consistent dialect throughout call  
âœ… **Local Processing** - Whisper STT and XTTS TTS run on your machine  
âœ… **Real-Time Conversation** - Microphone input â†’ Speaker output  
âœ… **Context-Aware Responses** - Remembers conversation history  

## Quick Start

### 1. Installation

```bash
# Clone or download the project files
cd ai-call-center

# Install dependencies
pip install -r requirements.txt

# This will install:
# - Gemini API client
# - Whisper (local STT)
# - XTTS (local TTS)
# - Audio processing libraries
```

**Note:** First run will download models (~2-3GB total):
- Whisper: ~150MB
- XTTS: ~2GB

### 2. Configuration

```bash
# Create .env file from template
cp .env.template .env

# Edit .env and add your Gemini API key
nano .env
```

Get your Gemini API key from: https://makersuite.google.com/app/apikey

### 3. Run

```bash
python main.py
```

## Usage

```
AI Call Center - Initializing...
============================================================
âœ“ Gemini 2.5 Flash initialized
âœ“ Whisper STT loaded
âœ“ TTS loaded on cuda
âœ“ Dialect detector & response generator ready

All systems ready!
============================================================

NEW CALL STARTED
Session ID: a1b2c3d4-5678-90ef-ghij-klmnopqrstuv
============================================================

Press Ctrl+C to end call
Press Enter to start each turn

[Press Enter when customer is ready to speak...]

--- Turn 1 ---
ğŸ¤ Listening for 5 seconds...
âœ“ Recording complete
ğŸ”„ Transcribing...
ğŸ“ Customer: Ø§Ø²ÙŠÙƒ ÙŠØ§ ÙÙ†Ø¯Ù…ØŒ Ø¹Ø§ÙŠØ² Ø§Ø³ØªÙØ³Ø± Ø¹Ù† Ø§Ù„Ø®Ø¯Ù…Ø©
ğŸ” Detected: egyptian (confidence: 0.95)
   Reasoning: Ø§Ø³ØªØ®Ø¯Ø§Ù… "Ø§Ø²ÙŠÙƒ" Ùˆ"Ø¹Ø§ÙŠØ²" Ù…Ù† Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©
âœ“ Dialect locked: egyptian (confidence: 0.95)
ğŸ”’ Dialect: egyptian (locked)
ğŸ’¬ Agent: Ø£Ù‡Ù„Ø§Ù‹ Ø¨ÙŠÙƒ! Ø§ØªÙØ¶Ù„ Ù‚ÙˆÙ„ Ù„ÙŠØŒ Ø¹Ø§ÙŠØ² ØªØ¹Ø±Ù Ø§ÙŠÙ‡ Ø¨Ø§Ù„Ø¸Ø¨Ø·ØŸ
ğŸ”Š Generating speech...
â–¶ï¸  Playing response...
âœ“ Turn 1 complete

[Press Enter when customer is ready to speak...]

--- Turn 2 ---
ğŸ¤ Listening for 5 seconds...
...
```

## Project Structure

```
ai-call-center/
â”œâ”€â”€ main.py                    # Main application
â”œâ”€â”€ session.py                 # Session management
â”œâ”€â”€ dialect_detector.py        # Gemini-based dialect detection
â”œâ”€â”€ response_generator.py      # Dialect-aware response generation
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                       # Configuration (create from .env.template)
â”œâ”€â”€ .env.template             # Configuration template
â””â”€â”€ README.md                 # This file
```

## System Requirements

### Minimum
- **CPU:** 4 cores
- **RAM:** 8GB
- **Storage:** 5GB free space
- **OS:** Windows, macOS, or Linux

### Recommended
- **GPU:** NVIDIA with 6GB+ VRAM (for faster TTS)
- **RAM:** 16GB
- **Storage:** 10GB free space

### Without GPU
The system works on CPU-only, just slower:
- Whisper: ~2-3 seconds (vs <1s on GPU)
- TTS: ~5-8 seconds (vs 2-3s on GPU)

## Supported Dialects

1. **Egyptian (Ù…ØµØ±ÙŠ)**
   - Keywords: Ø§Ø²ÙŠÙƒØŒ Ø¹Ø§ÙŠØ²ØŒ Ø§ÙŠÙ‡ØŒ Ø¯Ø§ØŒ Ø¯ÙŠ
   
2. **Gulf/Khaleeji (Ø®Ù„ÙŠØ¬ÙŠ)**
   - Keywords: Ø´Ù„ÙˆÙ†ÙƒØŒ Ø´Ù†ÙˆØŒ ÙˆÙŠØ´ØŒ ØªØ¨ØºÙ‰
   
3. **Levantine/Shami (Ø´Ø§Ù…ÙŠ)**
   - Keywords: ÙƒÙŠÙÙƒØŒ Ø´ÙˆØŒ Ù‡ÙŠÙƒØŒ Ø¨Ø¯Ùƒ
   
4. **Moroccan/Maghrebi (Ù…ØºØ±Ø¨ÙŠ)**
   - Keywords: ÙƒÙŠÙØ§Ø´ØŒ ÙˆØ§Ø´ØŒ Ø¨Ø²Ø§Ù
   
5. **Modern Standard Arabic (ÙØµØ­Ù‰)**
   - Keywords: ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŒ Ù…Ø§Ø°Ø§ØŒ Ù‡Ø°Ø§

## How It Works

### 1. Speech-to-Text (Whisper - Local)
Customer speaks â†’ Audio recorded â†’ Whisper transcribes to Arabic text

### 2. Dialect Detection (Gemini 2.5 Flash)
Transcribed text â†’ Gemini analyzes linguistic features â†’ Detects dialect

### 3. Session Locking
Once confidence â‰¥ 80% â†’ Dialect locked for entire conversation

### 4. Response Generation (Gemini 2.5 Flash)
Customer query + Detected dialect â†’ Gemini generates response in same dialect

### 5. Text-to-Speech (XTTS - Local)
Response text â†’ XTTS synthesizes speech â†’ Plays through speakers

## Configuration

### Adjust Recording Duration

In `main.py`, change:
```python
RECORDING_DURATION = 5  # Seconds per turn
```

### Change Whisper Model Size

Trade-off: Smaller = faster but less accurate

In `main.py`:
```python
WHISPER_MODEL_SIZE = "base"  # Options: tiny, base, small, medium, large
```

**Recommendations:**
- `tiny`: Very fast, ~60% accuracy
- `base`: Fast, ~75% accuracy âœ… **Default**
- `small`: Moderate, ~85% accuracy
- `medium`: Slow, ~90% accuracy

### Adjust Dialect Lock Threshold

In `session.py`:
```python
self.lock_threshold = 0.8  # 80% confidence required
```

## Cost Analysis

**Per Call (5 minutes, ~10 turns):**
- Whisper STT: $0 (local)
- Gemini 2.5 Flash: ~$0.001
  - Dialect detection: 10 calls Ã— $0.00005 = $0.0005
  - Response generation: 10 calls Ã— $0.00005 = $0.0005
- TTS: $0 (local with XTTS)

**Total: ~$0.001 per call** (essentially free!)

**For 1000 calls/day:**
- Daily: $1
- Monthly: ~$30

## Troubleshooting

### Microphone Not Working

```bash
# List available audio devices
python -c "import sounddevice as sd; print(sd.query_devices())"

# Set specific device in main.py
sd.default.device = 1  # Use device ID from list
```

### No Audio Output

```bash
# Test speakers
python -c "import sounddevice as sd; import numpy as np; sd.play(np.random.randn(16000), 16000); sd.wait()"
```

### Slow Performance

1. **Use smaller Whisper model:** Change to `tiny` or `base`
2. **Reduce recording duration:** Set to 3 seconds
3. **Use GPU:** Enable CUDA if available

### Dialect Detection Issues

**Problem:** Wrong dialect detected  
**Solution:** Text might be too short or ambiguous. System will improve accuracy over multiple turns.

**Problem:** Confidence too low  
**Solution:** Ask customer to speak more (longer utterances help)

## Advanced Features

### Add Custom Business Context

In `response_generator.py`, modify the system context:

```python
system_context = """
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙÙŠ Ø´Ø±ÙƒØ© [Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©].
Ù†Ø­Ù† Ù†Ù‚Ø¯Ù… Ø®Ø¯Ù…Ø§Øª: [Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª]
Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¹Ù…Ù„: [Ø§Ù„Ø£ÙˆÙ‚Ø§Øª]
"""

response = generator.generate(
    user_query=query,
    dialect=dialect,
    system_context=system_context
)
```

### Multiple Concurrent Calls

For production with multiple agents:

```python
import threading

def handle_multiple_calls(num_calls=5):
    threads = []
    for i in range(num_calls):
        agent = CallCenterAgent()
        thread = threading.Thread(target=agent.handle_call)
        thread.start()
        threads.append(thread)
    
    for thread in threads:
        thread.join()
```

### Call Recording & Analytics

Add to `session.py`:

```python
def save_call_recording(self, filepath):
    """Save conversation to file"""
    import json
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump({
            'session_id': self.session_id,
            'dialect': self.detected_dialect,
            'conversation': self.conversation_history
        }, f, ensure_ascii=False, indent=2)
```

## API Integration

### Flask REST API

```python
from flask import Flask, request, jsonify

app = Flask(__name__)
agent = CallCenterAgent()

@app.route('/detect_dialect', methods=['POST'])
def detect_dialect():
    text = request.json['text']
    dialect, confidence = agent.dialect_detector.detect(text)
    return jsonify({
        'dialect': dialect,
        'confidence': confidence
    })

@app.route('/generate_response', methods=['POST'])
def generate_response():
    query = request.json['query']
    dialect = request.json['dialect']
    response = agent.response_generator.generate(query, dialect)
    return jsonify({'response': response})
```

## Production Deployment

### Docker

```dockerfile
FROM python:3.10

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "main.py"]
```

### Environment Variables

For production, use environment variables instead of .env:

```bash
export GEMINI_API_KEY="your_key"
export RECORDING_DURATION="3"
export WHISPER_MODEL="base"
```

## Support & Contributing

For issues or questions, please check:
1. This README
2. Code comments in source files
3. The comprehensive guide: `AI_CALL_CENTER_GUIDE.md`

## License

This project is for educational and commercial use.

---

**Ready to start?** Just run `python main.py` and begin testing!
