"""
Dialect Detection using Gemini 2.5 Flash
Analyzes Arabic text to identify dialect without training
"""

import json
from typing import Tuple

class DialectDetector:
    """
    LLM-based dialect detector using Gemini
    Supports: Egyptian, Gulf, Levantine, Moroccan, MSA
    """
    
    DIALECT_PROMPT = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ­Ø¯Ø¯ Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø¨Ø¯Ù‚Ø©.

Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:
- Ù…ØµØ±ÙŠ (Egyptian) - Ø§Ø³ØªØ®Ø¯Ø§Ù…: Ø§Ø²ÙŠÙƒØŒ Ø¹Ø§ÙŠØ²ØŒ Ø§ÙŠÙ‡ØŒ Ø¯Ø§/Ø¯ÙŠØŒ Ø§Ù†Øª/Ø§Ù†ØªÙŠØŒ Ù…Ø¹Ù„Ø´ØŒ Ø¹Ø§Ù…Ù„ Ø§ÙŠÙ‡
- Ø®Ù„ÙŠØ¬ÙŠ (Gulf/Khaleeji) - Ø§Ø³ØªØ®Ø¯Ø§Ù…: Ø´Ù„ÙˆÙ†ÙƒØŒ Ø´Ù†ÙˆØŒ ÙˆÙŠØ´ØŒ Ø¹Ø³Ø§ÙƒØŒ ÙŠØ§Ù„Ù„Ù‡ØŒ ØªØ¨ØºÙ‰
- Ø´Ø§Ù…ÙŠ (Levantine) - Ø§Ø³ØªØ®Ø¯Ø§Ù…: ÙƒÙŠÙÙƒØŒ Ø´ÙˆØŒ Ù‡ÙŠÙƒØŒ Ù…Ù†ÙŠØ­ØŒ ÙŠÙ„Ø§ØŒ Ø¨Ø¯Ùƒ
- Ù…ØºØ±Ø¨ÙŠ (Moroccan/Maghrebi) - Ø§Ø³ØªØ®Ø¯Ø§Ù…: ÙƒÙŠÙØ§Ø´ØŒ ÙˆØ§Ø´ØŒ Ø¨Ø²Ø§ÙØŒ Ù…Ø²ÙŠØ§Ù†
- ÙØµØ­Ù‰ (Modern Standard Arabic) - Ø§Ø³ØªØ®Ø¯Ø§Ù…: ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŒ Ù…Ø§Ø°Ø§ØŒ Ù‡Ø°Ø§ØŒ Ø°Ù„Ùƒ

Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡: "{text}"

Ù‚Ù… Ø¨Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰:
1. Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙˆØ§Ù„Ù…ÙØ±Ø¯Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø©
2. Ø§Ù„ØªØ±Ø§ÙƒÙŠØ¨ Ø§Ù„Ù„ØºÙˆÙŠØ© ÙˆØ§Ù„Ù†Ø­ÙˆÙŠØ©
3. Ø§Ù„Ø£ÙØ¹Ø§Ù„ ÙˆØ§Ù„Ø¶Ù…Ø§Ø¦Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ Ø£Ùˆ Ø¹Ù„Ø§Ù…Ø§Øª markdown:
{{
    "dialect": "Ø§Ø³Ù… Ø§Ù„Ù„Ù‡Ø¬Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (egyptian/gulf/levantine/moroccan/msa)",
    "confidence": "Ø±Ù‚Ù… Ù…Ù† 0.0 Ø¥Ù„Ù‰ 1.0",
    "reasoning": "Ø³Ø¨Ø¨ Ù‚ØµÙŠØ± Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¯Ø§Ù„Ø©"
}}"""
    
    def __init__(self, model):
        """
        Initialize dialect detector
        
        Args:
            model: Gemini model instance
        """
        self.model = model
        self.supported_dialects = ['egyptian', 'gulf', 'levantine', 'moroccan', 'msa']
    
    def detect(self, text: str) -> Tuple[str, float]:
        """
        Detect Arabic dialect from transcribed text
        
        Args:
            text: Transcribed Arabic text
        
        Returns:
            Tuple of (dialect_name, confidence_score)
        """
        if not text or len(text.strip()) < 3:
            return 'msa', 0.3  # Default for very short text
        
        prompt = self.DIALECT_PROMPT.format(text=text)
        
        try:
            response = self.model.generate_content(prompt)
            result_text = response.text.strip()
            
            # Clean up response - remove markdown code blocks if present
            result_text = self._clean_json_response(result_text)
            
            # Parse JSON
            result = json.loads(result_text)
            
            dialect = result.get('dialect', 'msa').lower()
            confidence = float(result.get('confidence', 0.5))
            reasoning = result.get('reasoning', 'N/A')
            
            # Validate dialect
            if dialect not in self.supported_dialects:
                print(f"âš ï¸  Unknown dialect '{dialect}', defaulting to MSA")
                dialect = 'msa'
                confidence = 0.5
            
            print(f"ðŸ” Detected: {dialect} (confidence: {confidence:.2f})")
            print(f"   Reasoning: {reasoning}")
            
            return dialect, confidence
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON parsing error: {e}")
            print(f"   Raw response: {result_text[:100]}...")
            return 'msa', 0.5
            
        except Exception as e:
            print(f"âŒ Dialect detection error: {e}")
            return 'msa', 0.5
    
    def _clean_json_response(self, text: str) -> str:
        """Remove markdown formatting from JSON response"""
        # Remove ```json and ``` markers
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0]
        elif "```" in text:
            text = text.split("```")[1].split("```")[0]
        
        return text.strip()
    
    def batch_detect(self, texts: list) -> list:
        """
        Detect dialect for multiple texts
        Useful for analyzing conversation patterns
        
        Args:
            texts: List of Arabic texts
        
        Returns:
            List of (dialect, confidence) tuples
        """
        results = []
        for text in texts:
            dialect, confidence = self.detect(text)
            results.append((dialect, confidence))
        
        return results
